{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = sklearn.datasets.fetch_openml('mnist_784', data_home=\"mnist_784\")\n",
    "train_X = torch.tensor(mnist.data[:60000], dtype=torch.float) / 255\n",
    "train_Y = torch.tensor([int(x) for x in mnist.target[:60000]])\n",
    "val_X = torch.tensor(mnist.data[60000:], dtype=torch.float) / 255\n",
    "val_Y = torch.tensor([int(x) for x in mnist.target[60000:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  1\n",
      "tensor(0.2030, grad_fn=<DivBackward0>)\n",
      "epoch :  2\n",
      "tensor(0.0649, grad_fn=<DivBackward0>)\n",
      "epoch :  3\n",
      "tensor(0.0479, grad_fn=<DivBackward0>)\n",
      "epoch :  4\n",
      "tensor(0.0386, grad_fn=<DivBackward0>)\n",
      "epoch :  5\n",
      "tensor(0.0318, grad_fn=<DivBackward0>)\n",
      "epoch :  6\n",
      "tensor(0.0258, grad_fn=<DivBackward0>)\n",
      "epoch :  7\n",
      "tensor(0.0215, grad_fn=<DivBackward0>)\n",
      "epoch :  8\n",
      "tensor(0.0186, grad_fn=<DivBackward0>)\n",
      "epoch :  9\n",
      "tensor(0.0156, grad_fn=<DivBackward0>)\n",
      "epoch :  10\n",
      "tensor(0.0126, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "train_X = train_X.view(60000, 1, 28, 28)\n",
    "val_X = val_X.view(10000, 1, 28, 28)\n",
    "\n",
    "batch_size = 500\n",
    "lr = 0.0001\n",
    "epoch = 10\n",
    "train_X = train_X.view(batch_size, -1, 28, 28)\n",
    "train_Y = train_Y.view(batch_size, -1)\n",
    "\n",
    "LayerBlock = namedtuple('LayerBlock', ['num_repeats', 'num_filters', 'bottleneck_size'])\n",
    "blocks = [LayerBlock(3, 128, 32), LayerBlock(3, 256, 64), LayerBlock(3, 512, 128), LayerBlock(3, 1024, 256)]\n",
    "\n",
    "class Layers(nn.Module):\n",
    "    def __init__(self, filter, bottleneck):\n",
    "        super(Layers, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(filter, bottleneck, kernel_size=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(bottleneck, bottleneck, kernel_size=(3, 3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(bottleneck, filter, kernel_size=(1, 1)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.upscale = nn.Conv2d(filter, filter*2, kernel_size=(1, 1), bias=False)\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.ready = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=(7, 7), padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(3, 3), stride=1, padding=1),\n",
    "            nn.Conv2d(64, block[0].num_filters, kernel_size=(1, 1))\n",
    "        )\n",
    "        self.layer1 = Layers(block[0].num_filters, block[0].bottleneck_size)\n",
    "        self.layer2 = Layers(block[1].num_filters, block[1].bottleneck_size)\n",
    "        self.layer3 = Layers(block[2].num_filters, block[2].bottleneck_size)\n",
    "        self.linear = nn.Linear(1024*28*28, 10)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        out = self.ready(x)\n",
    "        out1 = self.layer1.layers(out)\n",
    "        output = out + out1\n",
    "        out = self.layer1.upscale(output)\n",
    "        out2 = self.layer2.layers(out)\n",
    "        output = out + out2\n",
    "        out = self.layer2.upscale(output)\n",
    "        out3 = self.layer3.layers(out)\n",
    "        output = out + out3\n",
    "        out = self.layer3.upscale(output)\n",
    "        out = torch.flatten(out, start_dim=1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "model = ResNet(blocks)\n",
    "model = nn.DataParallel(model)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "for ep in range(epoch):\n",
    "    print('epoch : ', ep+1)\n",
    "    avg_cost = 0\n",
    "    for batch in range(batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        X = train_X[batch]\n",
    "        X = X.unsqueeze(1)\n",
    "        y_pred = model.forward(X)\n",
    "        cost = loss(y_pred, train_Y[batch])\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost += cost\n",
    "    print(avg_cost / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.987\n"
     ]
    }
   ],
   "source": [
    "val_X = val_X.view(500, -1, 28, 28)\n",
    "T, F = 0, 0\n",
    "for i in range(500):\n",
    "    test_X = val_X[i]\n",
    "    test_X = test_X.unsqueeze(1)\n",
    "    test_pred = model.forward(test_X)\n",
    "    test_pred = test_pred.argmax(axis=1)\n",
    "\n",
    "    for j in range(len(test_pred)):\n",
    "        if test_pred[j] == val_Y[20*i+j]:\n",
    "            T += 1\n",
    "        else:\n",
    "            F += 1\n",
    "print(T / (T+F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
